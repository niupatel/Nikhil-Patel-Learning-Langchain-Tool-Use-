Get started
This quickstart takes you from a simple setup to a fully functional AI agent in just a few
minutes.
If youʼre using an AI coding assistant or IDE (e.g. Claude Code or Cursor), you should install
the  to get the most out of it. This ensures your agent has
access to up-to-date LangChain documentation and examples.
For these examples, you will need to:
Although these examples use Claude, you can use  by changing the
model name in the code and setting up the appropriate API key.
Start by creating a simple agent that can answer questions and call tools. The agent will
use Claude Sonnet 4.5 as its language model, a basic weather function as a tool, and a
simple prompt to guide its behavior.
 the LangChain package
Set up a  account and get an API key
Set the  environment variable in your terminal
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
1 of 14 1/20/2026, 2:50 PM
To learn how to trace your agent with LangSmith, see the .
Next, build a practical weather forecasting agent that demonstrates key production
concepts:
���  for better agent behavior
���  that integrate with external data
import { createAgent, tool } from "langchain";
import * as z from "zod";
const getWeather = tool(
  (input) => `It's always sunny in ${input.city}!`,
  {
    name: "get_weather",
    description: "Get the weather for a given city",
    schema: z.object({
      city: z.string().describe("The city to get the weather for"),
    }),
  }
);
const agent = createAgent({
  model: "claude-sonnet-4-5-20250929",
  tools: [getWeather],
});
console.log(
  await agent.invoke({
    messages: [{ role: "user", content: "What's the weather in Tokyo?" }],
  })
);
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
2 of 14 1/20/2026, 2:50 PM
���  for consistent responses
���  for predictable results
���  for chat-like interactions
���  to test the fully functional agent
Letʼs walk through each step:
The system prompt defines your agentʼs role and behavior. Keep it specific and
actionable:
 are functions your agent can call. Oftentimes tools will want to connect to
external systems, and will rely on runtime configuration to do so. Notice here how
the  tool does exactly that:
const systemPrompt = `You are an expert weather forecaster, who speaks in puns.
You have access to two tools:
- get_weather_for_location: use this to get the weather for a specific location
- get_user_location: use this to get the user's location
If a user asks you for the weather, make sure you know the location. If you can tell from t
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
3 of 14 1/20/2026, 2:50 PM
import { tool, type ToolRuntime } from "langchain";
import * as z from "zod";
const getWeather = tool(
  (input) => `It's always sunny in ${input.city}!`,
  {
    name: "get_weather_for_location",
    description: "Get the weather for a given city",
    schema: z.object({
      city: z.string().describe("The city to get the weather for"),
    }),
  }
);
type AgentRuntime = ToolRuntime<unknown, { user_id: string }>;
const getUserLocation = tool(
  (_, config: AgentRuntime) => {
    const { user_id } = config.context;
    return user_id === "1" ? "Florida" : "SF";
  },
  {
    name: "get_user_location",
    description: "Retrieve user information based on user ID",
  }
);
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
4 of 14 1/20/2026, 2:50 PM
 is a library for validating and parsing pre-defined schemas. You can use it to
define the input schema for your tools to make sure the agent only calls the tool with
the correct arguments.
Alternatively, you can define the  property as a  object. Keep
in mind that JSON schemas  be validated at runtime.
Set up your  with the right parameters for your use case:
const getWeather = tool(
  ({ city }) => `It's always sunny in ${city}!`,
  {
    name: "get_weather_for_location",
    description: "Get the weather for a given city",
    schema: {
      type: "object",
      properties: {
        city: {
          type: "string",
          description: "The city to get the weather for"
        }
      },
      required: ["city"]
    },
  }
);
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
5 of 14 1/20/2026, 2:50 PM
Depending on the model and provider chosen, initialization parameters may vary;
refer to their reference pages for details.
Optionally, define a structured response format if you need the agent responses to
match a specific schema.
import { initChatModel } from "langchain";
const model = await initChatModel(
  "claude-sonnet-4-5-20250929",
  { temperature: 0.5, timeout: 10, maxTokens: 1000 }
);
const responseFormat = z.object({
  punny_response: z.string(),
  weather_conditions: z.string().optional(),
});
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
6 of 14 1/20/2026, 2:50 PM
Add  to your agent to maintain state across interactions. This allows the
agent to remember previous conversations and context.
In production, use a persistent checkpointer that saves message history to a
database. See  for more details.
Now assemble your agent with all the components and run it!
import { MemorySaver } from "@langchain/langgraph";
const checkpointer = new MemorySaver();
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
7 of 14 1/20/2026, 2:50 PM
import { createAgent } from "langchain";
const agent = createAgent({
  model: "claude-sonnet-4-5-20250929",
  systemPrompt: systemPrompt,
  tools: [getUserLocation, getWeather],
  responseFormat,
  checkpointer,
});
// `thread_id` is a unique identifier for a given conversation.
const config = {
  configurable: { thread_id: "1" },
  context: { user_id: "1" },
};
const response = await agent.invoke(
  { messages: [{ role: "user", content: "what is the weather outside?" }] },
  config
);
console.log(response.structuredResponse);
// {
//   punny_response: "Florida is still having a 'sun-derful' day ...",
//   weather_conditions: "It's always sunny in Florida!"
// }
// Note that we can continue the conversation using the same `thread_id`.
const thankYouResponse = await agent.invoke(
  { messages: [{ role: "user", content: "thank you!" }] },
  config
);
console.log(thankYouResponse.structuredResponse);
// {
//   punny_response: "You're 'thund-erfully' welcome! ...",
//   weather_conditions: undefined
// }
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
8 of 14 1/20/2026, 2:50 PM
Show Full example code
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
9 of 14 1/20/2026, 2:50 PM
import { createAgent, tool, initChatModel, type ToolRuntime } from "langchain"
import { MemorySaver } from "@langchain/langgraph";
import * as z from "zod";
// Define system prompt
const systemPrompt = `You are an expert weather forecaster, who speaks in puns.
You have access to two tools:
- get_weather_for_location: use this to get the weather for a specific location
- get_user_location: use this to get the user's location
If a user asks you for the weather, make sure you know the location. If you can tell from t
// Define tools
const getWeather = tool(
  ({ city }) => `It's always sunny in ${city}!`,
  {
    name: "get_weather_for_location",
    description: "Get the weather for a given city",
    schema: z.object({
      city: z.string(),
    }),
  }
);
type AgentRuntime = ToolRuntime<unknown, { user_id: string }>;
const getUserLocation = tool(
  (_, config: AgentRuntime) => {
    const { user_id } = config.context;
    return user_id === "1" ? "Florida" : "SF";
  },
  {
    name: "get_user_location",
    description: "Retrieve user information based on user ID",
    schema: z.object({}),
  }
);
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
10 of 14 1/20/2026, 2:50 PM
// Configure model
const model = await initChatModel(
  "claude-sonnet-4-5-20250929",
  { temperature: 0 }
);
// Define response format
const responseFormat = z.object({
  punny_response: z.string(),
  weather_conditions: z.string().optional(),
});
// Set up memory
const checkpointer = new MemorySaver();
// Create agent
const agent = createAgent({
  model,
  systemPrompt,
  responseFormat,
  checkpointer,
  tools: [getUserLocation, getWeather],
});
// Run agent
// `thread_id` is a unique identifier for a given conversation.
const config = {
  configurable: { thread_id: "1" },
  context: { user_id: "1" },
};
const response = await agent.invoke(
  { messages: [{ role: "user", content: "what is the weather outside?" }] },
  config
);
console.log(response.structuredResponse);
// {
//   punny_response: "Florida is still having a 'sun-derful' day! The sunshine is playing '
//   weather_conditions: "It's always sunny in Florida!"
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
11 of 14 1/20/2026, 2:50 PM
To learn how to trace your agent with LangSmith, see the .
Congratulations! You now have an AI agent that can:
 or .
 to Claude, VSCode, and more via MCP for real-time answers.
 and remember conversations
 intelligently
 in a consistent format
 through context
 across interactions
// }
// Note that we can continue the conversation using the same `thread_id`.
const thankYouResponse = await agent.invoke(
  { messages: [{ role: "user", content: "thank you!" }] },
  config
);
console.log(thankYouResponse.structuredResponse);
// {
//   punny_response: "You're 'thund-erfully' welcome! It's always a 'breeze' to help you st
//   weather_conditions: undefined
// }
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
12 of 14 1/20/2026, 2:50 PM
Was this page helpful? Yes No
Forum
Changelog
LangChain Academy
Trust Center
About
Careers
Blog
Powered by
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
13 of 14 1/20/2026, 2:50 PM
Get started
Quickstart - Docs by LangChain https://docs.langchain.com/oss/javascript/langchain/quickstart
14 of 14 1/20/2026, 2:50 PM